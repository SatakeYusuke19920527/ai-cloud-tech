# 第 1 章 人工知能（AI）とは

---

## 1.1 人工知能（AI）の定義

### 人工知能とはなにか

人工知能（AI）とは、推論・認識・判断など、人間が行う知的な処理をコンピュータで実現しようとする技術のことである。

### 人工知能の大まかな分類

人工知能を、周囲の状況（入力）によって行動（出力）を変えるエージェント（プログラム）として捉えると、AIは4つのレベルに分類できる。

#### ● レベル1：単純な制御プログラム
すべての振る舞いがあらかじめ決められており、その通りに動くだけの技術  
例：エアコンの温度調節、洗濯機の水量調整、シェーバーの深剃り調整

#### ● レベル2：古典的な人工知能
探索、推論、知識データを利用し、状況に応じて複雑なふるまいをする技術

#### ● レベル3：機械学習を取り入れた人工知能
大量のサンプルデータから入力と出力の関係を学習する技術

### AI効果

AIで新しいことができるようになると、その仕組みが分かった途端に「それは知能ではなく単なる自動化だ」と考えてしまう心理現象を AI効果と呼ぶ。

### 人工知能とロボットの違い

人工知能とロボットは明確に異なる。  
ロボットという「身体」を動かすための“知的な処理を行う脳”が人工知能である。

---

## 1.2 人工知能研究の歴史

### 世界初の汎用コンピュータの誕生
1946年、アメリカのペンシルバニア大学でエニアック（ENIAC）が開発された。

### ダートマス会議
人工知能という言葉は、1956年に開催されたダートマス会議で初めて使用された。

その会議では、世界初の人工知能プログラム「ロジック・セオリスト」のデモンストレーションが行われ、コンピュータが数学の定理を自動的に証明できることが示された。

### ● 第1次AIブーム（1950年代後半〜1960年代）
記号処理と探索を用いた推論型AIが中心。  
迷路解き・定理証明などのトイ・プロブレムでは成果が出たが、複雑な現実問題を解けず失速し、AI研究は冬の時代へ。

### ● 第2次AIブーム（1980年代）
知識ベースを利用するエキスパートシステムが普及。  
日本では第五世代コンピュータが推進されたが、知識の管理の難しさが課題となり再び冬の時代へ。

### ● 第3次AIブーム（2010年〜）
ビッグデータと機械学習が実用化され、さらにディープラーニングが登場したことでAIの性能が飛躍的に向上した。

2010年代中ごろから生成AIが急速に発展し、大規模言語モデル（LLM）を用いたサービスが実用化された。  
一部の専門家は、ChatGPTの登場をきっかけに「第4次AIブーム」へ突入したと考えている。

---

## 1.3 人工知能分野の問題

### トイ・プロブレム（おもちゃの問題）
現実の問題をそのままコンピュータで解こうとすると困難なため、本質を損なわない範囲で簡略化した問題設定をトイ・プロブレムと呼ぶ。

しかし、トイ・プロブレムは現実世界の複雑性や不確実性を無視しており、現実問題にそのまま適用できないことが課題である。

### フレーム問題
フレーム問題は、1969年にジョン・マッカーシーとパトリック・ヘイズが提唱した人工知能における重要な未解決問題である。

これは「今行おうとしている行動に関係のある情報だけを、膨大な情報の中から適切に選び出すことが非常に難しい」という問題を指す。

### チューリングテスト（人工知能ができたかどうかを判定する方法）

人工知能に知能があるかどうかを判定する方法として、イギリスの数学者 アラン・チューリング が提唱した チューリングテスト が有名である。

このテストでは、人間がコンピュータと会話したときに 相手がコンピュータだと見抜けなければ、そのコンピュータには知能がある と判断される。

1966年にジョセフ・ワイゼンバウムが開発した イライザ（ELIZA） は、心理療法士の役割を演じて人間と会話するプログラムであり、人とコンピュータが会話した最初期の例である。中には、本物のセラピストだと信じてしまう人もいた。

また1991年以降、チューリングテストに合格する会話プログラムを目指した ローブナーコンテスト が毎年開催されている。

### 強いAIと弱いAI

「強いAI」「弱いAI」という言葉は、アメリカの哲学者 ジョン・サール が1980年に発表した論文
「Minds, Brains, and Programs」 の中で提示された区分である。

強いAI とは、適切にプログラムされたコンピュータは人間と同じ意味で心を持ち、プログラムそのものが、人間の思考や理解の仕組みを説明するものになると考える立場である。
この立場では、人間の心や脳の働きは情報処理であり、本物の心を持つ人工知能はコンピュータで実現できると考える。

弱いAI とは、コンピュータは人間の心を持つ必要はなく、人間の知的活動を模倣し、問題解決を行う便利な道具であればよいとする立場である。

ジョン・サールは、弱いAIは実現可能だが、意識や意味理解を持つ「強いAI」は実現不可能である と主張した。
この考えを説明するために、彼は 「中国語の部屋」 という思考実験を提示した。

この思考実験は「中国語の部屋」と呼ばれる。
ある部屋に英語しか理解できない人が閉じ込められており、部屋の中には中国語の質問に正しく答えるための完璧なマニュアルが用意されている。

部屋の外の人が中国語で質問を送ると、部屋の中の人はマニュアルに従って記号を操作し、中国語の答えを返す。その結果、外の人から見ると、部屋の中の人は中国語を理解して会話しているように見える。

しかし実際には、部屋の中の人は中国語の意味をまったく理解しておらず、単にマニュアルに従って記号を処理しているだけである。つまり、正しい受け答えができていても、それは「理解している」ことにはならない。

このことからサールは、チューリングテストに合格するような振る舞いができても、本当に知能や心を持っているとは限らないと主張した。
この思考実験は、心や意味がどこに存在するのか、またコンピュータが意味を理解できるのかという問題を考えるためのものである。

ジョン・サールはこの実験を通して、コンピュータは記号操作はできるが、意味を理解する心（意味論）を持つことはできないとし、「強いAI」を否定した。

ほかには、数学者・物理学者のロジャー・ペンローズは、著書『皇帝の新しい心 ― コンピュータ・心・物理法則』の中で、人間の意識は脳内の微細な構造に生じる量子効果が関与している可能性があり、そのため現在の計算機（従来型コンピュータ）では「強いAI」は実現できないと主張している。
