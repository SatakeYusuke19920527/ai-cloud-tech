# 第 1 章 人工知能（AI）とは

---

## 1.1 人工知能（AI）の定義

###　人工知能とはなにか

**人工知能**（AI）とは、推論・認識・判断など、人間が行う知的な処理をコンピュータで実現しようとする技術のことである。

### 人工知能の大まかな分類

人工知能を、**周囲の状況（入力）によって行動（出力）を変えるエージェント（プログラム）**として捉えると、AI は 4 つのレベルに分類できる。

### ● レベル 1：単純な制御プログラム

すべての振る舞いがあらかじめ決められており、その通りに動くだけの技術

例：エアコンの温度調節、洗濯機の水量調整、シェーバーの深剃り調整

### ● レベル 2：古典的な人工知能

探索、推論、知識データを利用することで、状況に応じて極めて複雑なふるまいをする技術

### ● レベル 3：機械学習を取り入れた人工知能

非常に多くのサンプルデータをもとに入力と出力の関係を学習する技術

### ● レベル 4：ディープラーニングを取り入れた人工知能

**ディープラーニング**は、**特徴量**（機械学習の対象となるデータの、**どのような特徴が学習結果に大きく影響するか**）を自動的に学習する技術

機械学習では、学習の対象となるデータの**特徴量**を知ることはとても重要である。

この**特徴量と呼ばれる変数を、自動的に学習する**サービスや製品がこのカテゴリに属する。

![](/images/)

### AI 効果

AIで新しいことができるようになると、その仕組みが分かった途端に『これは知能じゃなくてただの自動化だ』と思ってしまう人間の心理のことを **AI効果**と呼ぶ

### 人工知能とロボットの違い

人工知能とロボットは、明確に異なる。

簡単にいうと、ロボットの「脳」にあたる**考える（知的な処理）**部分という、目に見えない仕組みが人工知能である。

---

## 1.2 人工知能研究の歴史

### 世界初の汎用コンピュータの誕生

1946年、アメリカのペンシルバニア大学で**エニアック（ENIAC）**という電算機が開発された。

### ダートマス会議

人工知能という言葉は、1956年に開催された**ダートマス会議**で初めて使用された。

その会議では、世界初の人工知能プログラムである**ロジック・セオリスト**がデモンストレーションされ、コンピュータが数学の定理を自動的に証明可能であると示された。

### ● 第 1 次 AI ブーム（1950年代後半~1960年代）

1950年代後半〜1960年代は、記号処理と探索を用いた「推論型AI」が中心で、迷路解きや数学の定理証明といった**簡単な問題（トイ・プロブレム）**では大きな成果が得られた。

しかし1970年代に入ると、こうした手法では複雑で現実的な問題を解けないことが明らかになり、第一次AIブームは急速に冷めAI研究は冬の時代を迎えた。

### ● 第 2 次 AI ブーム（1980年代）

第2次AIブームでは、大量の専門知識をデータベースに蓄積して推論する「**エキスパートシステム**」とよばれる実用的なシステムが多く作られた。

日本でも、政府主導の大型計画「**第五世代コンピュータ**」が推進され、AI研究が活発化した。

しかし1990年代半ばになると、知識の蓄積・管理が非常に難しいことが明らかになり、AIは再び冬の時代へと突入した。

### ● 第 3 次 AI ブーム（2010 年〜）

第3次AIブームでは、**ビッグデータ**を用いて人工知能が自ら知識を獲得する「**機械学習**」が広く実用化された。

さらに、データの中から重要な情報（特徴量）を人間が設計するのではなく、**AI自身が自動的に見つけ出す**「**ディープラーニング（深層学習）**」が登場した。

これにより、人工知能が人間の知性を超える可能性（**シンギュラリティ**）への不安と期待が大きく高まった。

2010年代中ごろから、**画像・音楽・文章などの創造的なコンテンツを生み出す**「**生成AI**」の研究が活発になった。

自然言語処理の分野では、**自然な文章を生成できる**「**大規模言語モデル**（**Large Language Model：LLM**）」と呼ばれる技術が登場し、これを応用したさまざまなサービスが実用化された。

一部の専門家は、ChatGPT の登場をきっかけに、AIは「第4次AIブーム（生成AIの時代）」へ突入したと考えている。

---

## 1.3 人工知能分野の問題

### 人工知能分野の問題

### トイ・プロブレム（おもちゃの問題）

現実の問題をいきなりコンピュータで解こうとしても、うまくいかないのが普通である。

そこで、本質を損なわない範囲で問題を簡略化し、コンピュータでも扱える形にしたものを「**トイ・プロブレム**（**おもちゃの問題**）」と呼ぶ。

トイ・プロブレムは問題を簡略化してAIの学習に用いられるが、現実世界の複雑さや不確実性を無視している点が課題である。例えば、掃除ロボットの例では、トイ・プロブレムでは「どの部屋にいるか」と「確実に掃除できる」と仮定するが、現実では移動や掃除に失敗する可能性があり、状態や行動も膨大で連続的である。このため、トイ・プロブレムでうまくいった手法も、現実問題にそのまま適用することは難しい。

### フレーム問題

**フレーム問題**は、1969年にジョン・マッカーシーとパトリック・ヘイズによって提唱した、いまだに本質的な解決がされていない、人工知能における重要な課題である。

フレーム問題は、「**今しようとしていることに関係のあることがらだけを選び出すことが、実は非常に難しい**」ことを指す。

### チューリングテスト（人工知能ができたかどうかを判定する方法）

人工知能に知能があるかどうかを判定する方法として、イギリスの数学者**アラン・チューリング**が提唱した**チューリングテスト**が有名である。

このテストでは、**人間がコンピュータと会話したときに 相手がコンピュータだと見抜けなければ、そのコンピュータには知能がある**と判断される。

1966年にジョセフ・ワイゼンバウムが開発した **イライザ**（**ELIZA**） は、心理療法士の役割を演じて人間と会話するプログラムであり、人とコンピュータが会話した最初期の例である。中には、本物のセラピストだと信じてしまう人もいた。

また1991年以降、チューリングテストに合格する会話プログラムを目指した**ローブナーコンテスト**が毎年開催されている。

### 強いAIと弱いAI

「**強いAI**」「**弱いAI**」という言葉は、アメリカの哲学者**ジョン・サール**が1980年に発表した論文
「Minds, Brains, and Programs」 の中で提示された区分である。

強いAI とは、**適切にプログラムされたコンピュータは人間と同じ意味で心を持ち、プログラムそのものが、人間の思考や理解の仕組みを説明するものになると考える立場である。**
**この立場では、人間の心や脳の働きは情報処理であり、本物の心を持つ人工知能はコンピュータで実現できると考える。**

弱いAI とは、**コンピュータは人間の心を持つ必要はなく、人間の知的活動を模倣し、問題解決を行う便利な道具であればよいとする立場である。**

ジョン・サールは、弱いAIは実現可能だが、意識や意味理解を持つ「強いAI」は実現不可能である と主張した。
この考えを説明するために、彼は 「**中国語の部屋**」 という思考実験を提示した。

この思考実験は「中国語の部屋」と呼ばれる。
ある部屋に英語しか理解できない人が閉じ込められており、部屋の中には中国語の質問に正しく答えるための完璧なマニュアルが用意されている。

部屋の外の人が中国語で質問を送ると、部屋の中の人はマニュアルに従って記号を操作し、中国語の答えを返す。その結果、外の人から見ると、部屋の中の人は中国語を理解して会話しているように見える。

しかし実際には、部屋の中の人は中国語の意味をまったく理解しておらず、単にマニュアルに従って記号を処理しているだけである。つまり、正しい受け答えができていても、それは「理解している」ことにはならない。

![](/images/)

このことからサールは、チューリングテストに合格するような振る舞いができても、本当に知能や心を持っているとは限らないと主張した。
この思考実験は、心や意味がどこに存在するのか、またコンピュータが意味を理解できるのかという問題を考えるためのものである。

ジョン・サールはこの実験を通して、コンピュータは記号操作はできるが、意味を理解する心（意味論）を持つことはできないとし、「強いAI」を否定した。

ほかには、数学者・物理学者の**ロジャー・ペンローズ**は、著書『皇帝の新しい心 ― コンピュータ・心・物理法則』の中で、人間の意識は脳内の微細な構造に生じる量子効果が関与している可能性があり、そのため現在の計算機（従来型コンピュータ）では「強いAI」は実現できないと主張している。

### シンボルグラウンディング問題（記号接地問題）

**シンボルグラウンディング問題**とは、1990年に認知科学者**スティーブ・ハルナッド**が提起した、「**コンピュータが扱う記号**（**言葉や文字**）**が、どのようにして現実世界の物事や意味と結びつくのか**」という問題であり、人工知能や認知科学における重要な課題である。

たとえばリンゴを考える。
人間はリンゴを見たことがあり、触った感触や甘さ、匂いを知っているので、「リンゴ」という言葉を聞くと、それらの体験が自然に結びつく。
一方AIは、「リンゴ＝果物」「赤い」「甘い」といった言葉同士の関係は知っていても、実際の味や匂いを感じて理解しているわけではない。

このように、言葉（記号）が現実の感覚や体験と結びついていないという問題を、**シンボルグラウンディング問題**という。

### 身体性

知能が成立するには**身体が不可欠**であるという考え方がある。

赤ちゃんは、生まれたときから言葉や知識を理解しているわけではなでも
手を伸ばして物をつかむ、口に入れる、転ぶ、といった身体を使った経験を通して、「これは硬い」「これは痛い」「これはおもちゃだ」と学んでいく。

もし身体がなく、見ることも触ることもできなければ、本当の意味で理解することはできない。
「外界と相互作用できる身体がないと、概念はとらえきれない」というのが、身体性というアプローチの考え方である。

### 知識獲得のボトルネック

**機械翻訳**は、人工知能研究の初期から長年取り組まれてきた課題である。
1970年代後半には、文法規則や辞書を人手で定義する**ルールベース機械翻訳**が主流であった。
その後、1990年代以降になると、大量の翻訳データをもとに確率的に訳文を生成する**統計的機械翻訳**が登場し、翻訳精度は大きく向上した。

しかし、それでもなお翻訳の品質には限界があり、完全に実用的とは言えなかった。
その最大の理由は、コンピュータが文の「意味」を理解しているわけではなく、あくまで表面的なパターン処理を行っているにすぎない点にある。

例えば、機械翻訳で
「りんごは赤い」
という文を考える。

人間は、りんごを見たり触ったりした経験があるので、「りんごは果物で、多くの場合赤い」と自然に理解できる。
そのため、英語でも
“An apple is red.”
と迷わず訳せる。

しかしコンピュータは、りんごを見たことも触ったこともなく、「赤い」とはどんな色かも知らない。
ただ単に、単語の対応関係をもとに機械的に処理しているだけである。

このように、人間にとって当たり前の知識や経験を、人工知能に教えるのはとても難しい。
これを**知識獲得のボトルネック**と呼ぶ。

2010年頃から、**ニューラル機械翻訳**（人間が言葉を理解するのと同じような構造で訳文を出力するといわれている）というディープラーニングを応用した機械翻訳が登場したことにより機械翻訳の品質が格段に向上したことが大きな話題となった。

これに続き2018年以降は「大規模言語モデル」と呼ばれる技術も登場した。
翻訳の分野でもディープラーニングが利用されるようになり、知識獲得のボトルネックを乗り越え、人間と同等かそれ以上の翻訳機の実現が期待されている。



=======
## 1.3 AI・機械学習・ディープラーニングの関係

| Head | Head | Head |
| ---- | ---- | ---- |
| Text | Text | Text |
| Text | Text | Text |

```js
test;
```

## ここに画像表示 
![](buri.png)
![](buri.png=100x)
![](chinese_room.png)

$$
e^{i\theta} = \cos\theta + i\sin\theta
$$

> 引用文
> 引用文


---

:::message
メッセージをここに
:::

:::warning
注意
:::

:::success
成功
:::

:::alert
警告
:::


