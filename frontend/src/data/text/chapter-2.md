# 第 2 章　人工知能をめぐる動向

---

## 探索・推論

### 迷路（探索木）

迷路のように分かれ道があり、スタートからゴールまでの経路を見つける問題は探索の問題と考えることができる。

このような問題を**コンピュータで処理するためには、最初に行うことを決め、次にどこを調べるかという手順を定める**必要がある。

分岐があるところと、行き止まりのところに注目すると、行き止まりのところに到達した場合には、別の分岐点に戻って探索を続ける。

迷路の道を取りまとめて、分岐点と通路の関係を構造として表すことができる。このような構造を**探索木**と呼ぶ。

![](tansaku.png=100x)

探索木をスタートからたどり、ゴールにたどり着く経路を探す。

探索木とは、要するに場合わけです。場合わけを続けていれば、いつか目的の条件に合致するものが出現するという考えを軸としている。

探索木は、探索する順序によって、見つかる経路や探索にかかる時間が変わる。

探索方法として、代表的なものに**幅優先探索**と**深さ優先探索**がある。

### 幅優先探索

幅優先探索では、出発点に近いノード（探索木の各要素）を順に探索する。

出発点から遠いノードほど後で探索される。

この方法では、**最短距離でゴールに到達する解**を見つけることができるが、探索の途中で記憶しておくノードが多くなり複雑になれば**メモリ不足**で処理が続行できなくなる可能性がある。

### 深さ優先探索

深さ優先探索では、1つのノードから行けるところまで進み、行き止まりになったら戻って別の経路を探索する。

この方法では、記憶しておくノードの数は少なく**メモリはあまり必要ない**が、最短距離の経路が見つかるとは限らない。

### ハノイの塔

探索を使って**ハノイの塔**というパズルを解くことができる。

このパズルは、3本のポールがあり、最初はすべて左側のポールに円盤が積み重なっている。

円盤は一度に1枚ずつしか移動させることができない。

また、小さな円盤の上に大きな円盤を置くことはできない。

このルールに従い、すべての円盤を右端のポールに移動できればパズルの完成である。

![](hanoi.png=100x)

（P,R,Q）は、一番小さい円盤がP、次の円盤がR、一番大きな円盤がQにある状態を表している。

このように、ハノイの塔の状態は円盤の位置の組として表現できる。

すべての円盤をルールに従って右側のポールに移動するパスは複数存在するが。最短で移動させるにはこの探索木の一番？？？側を選択すればよい。

### ロボットの行動計画

ロボットの行動計画は、探索を使って考えることができる。

このように、ロボットが目的を達成するまでの行動を考える技術を**プランニング**と呼ぶ。

ロボットがいる場所や、部屋が掃除されているかどうかなど、ロボットを取り巻く状況全体をまとめて1つの状態と考える。

そして、ある状態から別の状態へ変わることを、ロボットの行動として表す。

このようにして作られた、「状態」と「行動」のつながり全体を探索空間という。

部屋は2つあり、Room1 と Room2 としてロボットは、Room1 または Room2 のどちらかにいて、各部屋は「清掃済み」か「未清掃」のどちらかである
、という情報によって、状態が決まる。

最初、ロボットは清掃済みのRoom1にいて、ロボットは次の行動を取ることができる。

左に移動する

右に移動する

今いる部屋を清掃する

行動を行うと、ロボットの位置や部屋の状態が変わり、別の状態へ移る。

ロボットに「すべての部屋をできるだけ短い時間で清掃しなさい」という命令を与えた場合、探索によって目標とする状態に至る行動計画を求めることができる。

そのために、ロボットの行動を前提条件・行動・結果の3つで記述する。例えば、ロボットが清掃済みのRoom1にいる状態で右に移動すると、未清掃のRoom2にいる状態になる。

![](robotcleaning.png=100x)

また、ロボットが未清掃のRoom2にいる状態で清掃を行うと、その部屋は清掃済みの状態になる。このように、すべての状態について行動を記述しておくことで、目標状態に至る行動計画を立てることができる。

このような〈前提条件〉〈行動〉〈結果〉の組で行動を表す方法は、**STRIPS（Stanford Research Institute Problem Solver）**  と呼ばれている。

**SHRDLU**は、1968年から1970年にかけて**テリー・ウィノグラード**によって開発されたシステムである。SHRDLU では、「積み木の世界」と呼ばれる限られた世界を対象として、英語による指示を理解し、その指示に従って物体を操作することができた。積み木の世界には、立方体や四角錐などの物体があり、それらの位置関係が定義されている。

SHRDLU は、与えられた指示がその世界の中で実行可能かどうかを判断し、可能であれば実際に物体を動かすことができた。また、「どの物体がどこにあるか」といった質問に対して、現在の状態に基づいて答えることもできた。

このように SHRDLU は、限定された世界ではあるが、自然な会話をすることができた。この成果はの後に**Cyeプロジェクト**にも引き継がれている。


### ボードゲーム（オセロ・チェス・将棋・囲碁）

2016年，囲碁の世界トップ棋士に対して，人工知能プログラム AlphaGo（アルファ碁） が勝利し，大きな話題となった。

ボードゲームをコンピュータで解く基本は探索だが、その数が天文学的な数字になってしまうため、事実上すべてを探索しきれないという問題がある。

チェスや将棋ではすでにコンピュータが人間のトップレベルに達していたが，組み合わせの数が特に多い囲碁では困難と考えられており、トップレベルに達するには後10年以上はかかる

そこで、効率よく探索するため**コスト**の概念を取り入れる。

効率よく探索するため，経験的に有効な知識を用いることを
**ヒューリスティックな知識**（ここでの「ヒューリスティック」は「経験的な」「発見的な」という意味ではなく、「探索を効率化するのに有効な」という意味で呼んでいる）という。

ボードゲームの戦略決定には**Mini-Max法**が用いられる。

自分の番では，コストが最大になる手を選ぶ

相手の番では，コストが最小になる手を相手が選ぶ

未来の局面から現在の局面に向けて逆算して，各ノードの値を決定し，
現在の局面で自分が選ぶべき最善手を求める方法。

Mini-Max法では探索量が膨大になるため，
不要な枝を調べないようにする方法として
**αβ法（アルファ・ベータ法）**が用いられる。

α値は自分側がこれ以上悪くならない下限値

β値は相手側がこれ以上良くならない上限値

探索の途中で，ある枝の評価がすでにαより悪いことが分かった場合，
その枝はそれ以上調べる必要がなくなる。
この打ち切りを**αカット**という。

同様にβによる打ち切りも行われる。

αβ法により，Mini-Max法と同じ最善手を保ったまま，
探索量を大幅に減らすことができる。